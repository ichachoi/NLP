# -*- coding: utf-8 -*-
"""NLP_0182180150-46

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KDYC9SZaGf-Ua8YJcrkN5TTNvVdSMgPY
"""

import pandas as pd

df = pd.read_csv("train.txt", sep=";")

df.head()

df.columns = ['sentence', 'emotion']

df.head()

category = pd.get_dummies(df.emotion)
df_baru = pd.concat([df, category], axis=1)
df_baru = df_baru.drop(columns='emotion')
df_baru

komentar = df_baru['sentence'].values
emosi = df_baru[['anger', 'fear', 'joy', 'love', 'sadness', 'surprise']].values

from sklearn.model_selection import train_test_split
komentar_latih, komentar_test, emosi_latih, emosi_test = train_test_split(komentar, emosi, test_size=0.2)

from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences

tokenizer = Tokenizer(num_words=5000, oov_token='x')
tokenizer.fit_on_texts(komentar_latih) 
tokenizer.fit_on_texts(komentar_test)

sekuens_latih = tokenizer.texts_to_sequences(komentar_latih)
sekuens_test = tokenizer.texts_to_sequences(komentar_test)

padded_latih = pad_sequences(sekuens_latih) 
padded_test = pad_sequences(sekuens_test)

import tensorflow as tf
model = tf.keras.Sequential([
    tf.keras.layers.Embedding(input_dim=5000, output_dim=16),
    tf.keras.layers.LSTM(64),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(6, activation='softmax')

])
model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])

num_epochs = 10
class myCallback (tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('accuracy')>0.80):
      print('\nAkurasi telah mencapai >80%!')
      self.model.stop_training=True

callbacks = myCallback()
history = model.fit(padded_latih, emosi_latih, epochs=num_epochs, 
                    validation_data=(padded_test, emosi_test), verbose=2)